{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b127c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 7.61MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 242kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.09MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.15MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAC-Bayes GAN の学習を開始します...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 469/469 [00:11<00:00, 42.47it/s, D Loss=0.0030, G (R_n)=8.0962, KL=31638.93, Penalty=0.5136] \n",
      "Epoch 2/50: 100%|██████████| 469/469 [00:11<00:00, 41.01it/s, D Loss=0.0734, G (R_n)=15.5193, KL=31888.12, Penalty=0.5156]\n",
      "Epoch 3/50: 100%|██████████| 469/469 [00:11<00:00, 41.53it/s, D Loss=0.2154, G (R_n)=9.3300, KL=32390.41, Penalty=0.5196] \n",
      "Epoch 4/50: 100%|██████████| 469/469 [00:11<00:00, 40.94it/s, D Loss=0.1825, G (R_n)=5.5684, KL=32740.10, Penalty=0.5224]\n",
      "Epoch 5/50: 100%|██████████| 469/469 [00:12<00:00, 38.59it/s, D Loss=0.1063, G (R_n)=11.4651, KL=33125.97, Penalty=0.5255]\n",
      "Epoch 6/50: 100%|██████████| 469/469 [00:11<00:00, 42.15it/s, D Loss=0.1043, G (R_n)=3.0560, KL=33516.70, Penalty=0.5286] \n",
      "Epoch 7/50: 100%|██████████| 469/469 [00:10<00:00, 42.89it/s, D Loss=0.3473, G (R_n)=12.6352, KL=33853.89, Penalty=0.5312]\n",
      "Epoch 8/50: 100%|██████████| 469/469 [00:11<00:00, 42.60it/s, D Loss=0.1380, G (R_n)=8.9974, KL=34131.94, Penalty=0.5334] \n",
      "Epoch 9/50: 100%|██████████| 469/469 [00:10<00:00, 43.22it/s, D Loss=0.1227, G (R_n)=13.4759, KL=34383.75, Penalty=0.5354]\n",
      "Epoch 10/50: 100%|██████████| 469/469 [00:10<00:00, 43.15it/s, D Loss=0.0761, G (R_n)=13.3464, KL=34636.48, Penalty=0.5373]\n",
      "Epoch 11/50: 100%|██████████| 469/469 [00:11<00:00, 40.39it/s, D Loss=0.0110, G (R_n)=12.3127, KL=34905.77, Penalty=0.5394]\n",
      "Epoch 12/50: 100%|██████████| 469/469 [00:11<00:00, 41.54it/s, D Loss=0.1758, G (R_n)=12.6576, KL=35078.02, Penalty=0.5407]\n",
      "Epoch 13/50: 100%|██████████| 469/469 [00:10<00:00, 44.21it/s, D Loss=0.0083, G (R_n)=13.3720, KL=35224.44, Penalty=0.5419]\n",
      "Epoch 14/50: 100%|██████████| 469/469 [00:10<00:00, 44.22it/s, D Loss=0.1939, G (R_n)=5.6309, KL=35403.59, Penalty=0.5432] \n",
      "Epoch 15/50: 100%|██████████| 469/469 [00:10<00:00, 43.72it/s, D Loss=0.0257, G (R_n)=15.4271, KL=35532.39, Penalty=0.5442]\n",
      "Epoch 16/50: 100%|██████████| 469/469 [00:10<00:00, 43.71it/s, D Loss=0.0016, G (R_n)=15.4262, KL=35676.29, Penalty=0.5453]\n",
      "Epoch 17/50: 100%|██████████| 469/469 [00:10<00:00, 44.03it/s, D Loss=0.0287, G (R_n)=14.9263, KL=35796.58, Penalty=0.5462]\n",
      "Epoch 18/50: 100%|██████████| 469/469 [00:10<00:00, 43.39it/s, D Loss=0.0052, G (R_n)=16.0994, KL=35935.57, Penalty=0.5473]\n",
      "Epoch 19/50: 100%|██████████| 469/469 [00:11<00:00, 40.70it/s, D Loss=0.0083, G (R_n)=15.0306, KL=36059.84, Penalty=0.5482]\n",
      "Epoch 20/50: 100%|██████████| 469/469 [00:11<00:00, 42.21it/s, D Loss=0.0010, G (R_n)=16.7891, KL=36202.27, Penalty=0.5493]\n",
      "Epoch 21/50: 100%|██████████| 469/469 [00:10<00:00, 43.87it/s, D Loss=0.0107, G (R_n)=10.8703, KL=36340.76, Penalty=0.5504]\n",
      "Epoch 22/50: 100%|██████████| 469/469 [00:10<00:00, 43.53it/s, D Loss=0.0163, G (R_n)=13.3446, KL=36491.08, Penalty=0.5515]\n",
      "Epoch 23/50: 100%|██████████| 469/469 [00:10<00:00, 42.96it/s, D Loss=0.1892, G (R_n)=19.4419, KL=36550.01, Penalty=0.5520]\n",
      "Epoch 24/50: 100%|██████████| 469/469 [00:11<00:00, 41.90it/s, D Loss=0.0043, G (R_n)=12.5690, KL=36598.47, Penalty=0.5523]\n",
      "Epoch 25/50: 100%|██████████| 469/469 [00:10<00:00, 42.99it/s, D Loss=0.0024, G (R_n)=15.3658, KL=36642.84, Penalty=0.5527]\n",
      "Epoch 26/50: 100%|██████████| 469/469 [00:11<00:00, 40.21it/s, D Loss=0.0066, G (R_n)=12.6092, KL=36687.19, Penalty=0.5530]\n",
      "Epoch 27/50: 100%|██████████| 469/469 [00:11<00:00, 41.35it/s, D Loss=0.0093, G (R_n)=8.0963, KL=36708.96, Penalty=0.5532] \n",
      "Epoch 28/50: 100%|██████████| 469/469 [00:11<00:00, 42.47it/s, D Loss=0.0025, G (R_n)=11.2954, KL=36757.96, Penalty=0.5535]\n",
      "Epoch 29/50: 100%|██████████| 469/469 [00:11<00:00, 42.57it/s, D Loss=0.0319, G (R_n)=17.0723, KL=36823.02, Penalty=0.5540]\n",
      "Epoch 30/50: 100%|██████████| 469/469 [00:10<00:00, 42.66it/s, D Loss=0.0009, G (R_n)=24.4290, KL=36866.43, Penalty=0.5543]\n",
      "Epoch 31/50: 100%|██████████| 469/469 [00:11<00:00, 41.15it/s, D Loss=0.0106, G (R_n)=18.4418, KL=36887.86, Penalty=0.5545]\n",
      "Epoch 32/50: 100%|██████████| 469/469 [00:12<00:00, 38.21it/s, D Loss=0.0151, G (R_n)=12.7504, KL=36930.20, Penalty=0.5548]\n",
      "Epoch 33/50: 100%|██████████| 469/469 [00:11<00:00, 40.88it/s, D Loss=0.0815, G (R_n)=13.4252, KL=36891.70, Penalty=0.5545]\n",
      "Epoch 34/50: 100%|██████████| 469/469 [00:11<00:00, 39.88it/s, D Loss=0.0085, G (R_n)=19.5495, KL=36886.81, Penalty=0.5545]\n",
      "Epoch 35/50: 100%|██████████| 469/469 [00:11<00:00, 40.18it/s, D Loss=0.0138, G (R_n)=14.1137, KL=36857.37, Penalty=0.5543]\n",
      "Epoch 36/50: 100%|██████████| 469/469 [00:11<00:00, 41.08it/s, D Loss=0.0015, G (R_n)=17.0724, KL=36835.46, Penalty=0.5541]\n",
      "Epoch 37/50: 100%|██████████| 469/469 [00:11<00:00, 41.64it/s, D Loss=0.0005, G (R_n)=13.9618, KL=36803.60, Penalty=0.5539]\n",
      "Epoch 38/50: 100%|██████████| 469/469 [00:12<00:00, 37.41it/s, D Loss=0.0238, G (R_n)=28.4831, KL=36693.38, Penalty=0.5530]\n",
      "Epoch 39/50: 100%|██████████| 469/469 [00:11<00:00, 40.91it/s, D Loss=0.0011, G (R_n)=10.9894, KL=36589.25, Penalty=0.5523]\n",
      "Epoch 40/50: 100%|██████████| 469/469 [00:10<00:00, 44.06it/s, D Loss=0.0017, G (R_n)=14.5222, KL=36498.75, Penalty=0.5516]\n",
      "Epoch 41/50: 100%|██████████| 469/469 [00:10<00:00, 44.65it/s, D Loss=0.0028, G (R_n)=23.0846, KL=36369.73, Penalty=0.5506]\n",
      "Epoch 42/50: 100%|██████████| 469/469 [00:10<00:00, 43.21it/s, D Loss=0.0112, G (R_n)=11.1299, KL=36181.52, Penalty=0.5492]\n",
      "Epoch 43/50: 100%|██████████| 469/469 [00:10<00:00, 44.61it/s, D Loss=0.0003, G (R_n)=18.1231, KL=36020.90, Penalty=0.5480]\n",
      "Epoch 44/50: 100%|██████████| 469/469 [00:10<00:00, 44.82it/s, D Loss=0.0278, G (R_n)=20.8604, KL=35843.23, Penalty=0.5466]\n",
      "Epoch 45/50: 100%|██████████| 469/469 [00:10<00:00, 43.37it/s, D Loss=0.0009, G (R_n)=12.9624, KL=35715.21, Penalty=0.5456]\n",
      "Epoch 46/50: 100%|██████████| 469/469 [00:10<00:00, 44.73it/s, D Loss=0.0049, G (R_n)=27.0375, KL=35507.42, Penalty=0.5440]\n",
      "Epoch 47/50: 100%|██████████| 469/469 [00:10<00:00, 44.63it/s, D Loss=0.0012, G (R_n)=17.8872, KL=35309.02, Penalty=0.5425]\n",
      "Epoch 48/50: 100%|██████████| 469/469 [00:10<00:00, 44.90it/s, D Loss=0.0004, G (R_n)=14.2489, KL=35158.25, Penalty=0.5414]\n",
      "Epoch 49/50: 100%|██████████| 469/469 [00:10<00:00, 43.63it/s, D Loss=0.0042, G (R_n)=34.1920, KL=34997.32, Penalty=0.5401]\n",
      "Epoch 50/50: 100%|██████████| 469/469 [00:10<00:00, 44.99it/s, D Loss=0.0016, G (R_n)=14.1551, KL=34833.27, Penalty=0.5388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習完了。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- 0. ハイパーパラメータ ---\n",
    "BATCH_SIZE = 128\n",
    "NOISE_DIM = 100\n",
    "IMG_SIZE = 28\n",
    "IMG_DIM = IMG_SIZE * IMG_SIZE\n",
    "N_EPOCHS = 50\n",
    "LR = 0.001\n",
    "N_SAMPLES = 60000  # MNIST訓練データセットの総数\n",
    "DELTA = 0.05       # 95%の信頼度 (1 - delta)\n",
    "PAC_WEIGHT = 0.1   # PAC-Bayesペナルティの重み（要調整）\n",
    "\n",
    "# デバイス設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 出力ディレクトリ\n",
    "os.makedirs(\"pac_gan_images\", exist_ok=True)\n",
    "\n",
    "# --- 1. データの準備 ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # -1から1に正規化\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "data_loader = DataLoader(mnist_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# --- 2. Stochastic Generator (PAC-Bayes) ---\n",
    "# のバウンドを目的関数に使う\n",
    "class StochasticGenerator(nn.Module):\n",
    "    def __init__(self, noise_dim, output_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        \n",
    "        # --- 重みの「平均 (mu)」を定義 ---\n",
    "        self.mu_params = nn.ModuleDict({\n",
    "            'fc1_mu': nn.Linear(noise_dim, hidden_dim),\n",
    "            'fc2_mu': nn.Linear(hidden_dim, hidden_dim),\n",
    "            'fc3_mu': nn.Linear(hidden_dim, output_dim),\n",
    "        })\n",
    "        \n",
    "        # --- 重みの「標準偏差 (sigma)」の対数 (rho) を定義 ---\n",
    "        self.rho_params = nn.ModuleDict({\n",
    "            'fc1_rho': nn.Linear(noise_dim, hidden_dim),\n",
    "            'fc2_rho': nn.Linear(hidden_dim, hidden_dim),\n",
    "            'fc3_rho': nn.Linear(hidden_dim, output_dim),\n",
    "        })\n",
    "\n",
    "        # --- 事前分布 p(w) = N(0, 1) ---\n",
    "        self.prior_mu = 0.0\n",
    "        self.prior_sigma = 1.0\n",
    "\n",
    "    def sample_weights(self):\n",
    "        \"\"\"Reparameterization Trick で重みをサンプリング\"\"\"\n",
    "        sampled_weights = {}\n",
    "        for name, mu_layer in self.mu_params.items():\n",
    "            rho_layer = self.rho_params[name.replace('_mu', '_rho')]\n",
    "            \n",
    "            mu_w, mu_b = mu_layer.weight, mu_layer.bias\n",
    "            rho_w, rho_b = rho_layer.weight, rho_layer.bias\n",
    "            \n",
    "            # sigma = log(1 + exp(rho)) (Softplus)\n",
    "            sigma_w = F.softplus(rho_w)\n",
    "            sigma_b = F.softplus(rho_b)\n",
    "            \n",
    "            # epsilon ~ N(0, 1)\n",
    "            eps_w = torch.randn_like(mu_w)\n",
    "            eps_b = torch.randn_like(mu_b)\n",
    "            \n",
    "            # w = mu + sigma * epsilon\n",
    "            w = mu_w + sigma_w * eps_w\n",
    "            b = mu_b + sigma_b * eps_b\n",
    "            \n",
    "            sampled_weights[name.replace('_mu', '')] = (w, b)\n",
    "            \n",
    "        return sampled_weights\n",
    "\n",
    "    def forward(self, z, weights):\n",
    "        \"\"\"サンプリングされた重みで順伝播\"\"\"\n",
    "        w1, b1 = weights['fc1']\n",
    "        x = F.relu(F.linear(z, w1, b1))\n",
    "        \n",
    "        w2, b2 = weights['fc2']\n",
    "        x = F.relu(F.linear(x, w2, b2))\n",
    "        \n",
    "        w3, b3 = weights['fc3']\n",
    "        x = torch.tanh(F.linear(x, w3, b3)) # -1 ~ 1 の画像ピクセル\n",
    "        return x\n",
    "\n",
    "    def calculate_kl(self):\n",
    "        \"\"\"KL(q || p) を解析的に計算\"\"\"\n",
    "        kl_total = 0.0\n",
    "        \n",
    "        for name, mu_layer in self.mu_params.items():\n",
    "            rho_layer = self.rho_params[name.replace('_mu', '_rho')]\n",
    "            \n",
    "            for mu, rho in [(mu_layer.weight, rho_layer.weight), (mu_layer.bias, rho_layer.bias)]:\n",
    "                \n",
    "                sigma = F.softplus(rho)\n",
    "                q_dist = torch.distributions.Normal(mu, sigma)\n",
    "                p_dist = torch.distributions.Normal(self.prior_mu, self.prior_sigma)\n",
    "                \n",
    "                # GPU/CPUの互換性のために、事前分布を q_dist と同じデバイス、型にする\n",
    "                p_dist = torch.distributions.Normal(\n",
    "                    torch.full_like(mu, self.prior_mu), \n",
    "                    torch.full_like(sigma, self.prior_sigma)\n",
    "                )\n",
    "\n",
    "                kl_div = torch.distributions.kl.kl_divergence(q_dist, p_dist).sum()\n",
    "                kl_total += kl_div\n",
    "                \n",
    "        return kl_total\n",
    "\n",
    "# --- 3. Discriminator ---\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid() # 0 (Fake) ~ 1 (Real)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# --- 4. モデルと最適化の初期化 ---\n",
    "\n",
    "G = StochasticGenerator(NOISE_DIM, IMG_DIM).to(device)\n",
    "D = Discriminator(IMG_DIM).to(device)\n",
    "\n",
    "# D は通常通り学習\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=LR)\n",
    "# G は「重みの分布 (mu, rho)」を学習\n",
    "optimizer_G = optim.Adam(\n",
    "    list(G.mu_params.parameters()) + list(G.rho_params.parameters()), \n",
    "    lr=LR\n",
    ")\n",
    "\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "# McAllesterのバウンドの定数項\n",
    "# log(2 * sqrt(N) / delta)\n",
    "log_term = np.log(2 * np.sqrt(N_SAMPLES) / DELTA)\n",
    "\n",
    "# --- 5. 学習ループ ---\n",
    "\n",
    "print(\"PAC-Bayes GAN の学習を開始します...\")\n",
    "for epoch in range(N_EPOCHS):\n",
    "    pbar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
    "    for i, (real_imgs, _) in enumerate(pbar):\n",
    "        \n",
    "        batch_size = real_imgs.shape[0]\n",
    "        real_imgs = real_imgs.view(batch_size, -1).to(device)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # --- (1) Discriminator の学習 ---\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Real 画像\n",
    "        D_real_output = D(real_imgs)\n",
    "        loss_D_real = bce_loss(D_real_output, real_labels)\n",
    "        \n",
    "        # Fake 画像 (Generatorの重みをサンプリングして生成)\n",
    "        noise = torch.randn(batch_size, NOISE_DIM).to(device)\n",
    "        with torch.no_grad(): # Gの勾配は不要\n",
    "            sampled_weights_D_step = G.sample_weights()\n",
    "            fake_imgs = G(noise, sampled_weights_D_step) # <-- 修正済み\n",
    "        \n",
    "        D_fake_output = D(fake_imgs)\n",
    "        loss_D_fake = bce_loss(D_fake_output, fake_labels)\n",
    "        \n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --- (2) Generator の学習 (PAC-Bayes BBVI) ---\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # 1. 重みをサンプリング (Reparameterization Trick)\n",
    "        sampled_weights_G_step = G.sample_weights()\n",
    "        \n",
    "        # 2. 経験リスク R_n(q) の計算 (GANのG損失)\n",
    "        noise_G = torch.randn(batch_size, NOISE_DIM).to(device)\n",
    "        fake_imgs_G = G(noise_G, sampled_weights_G_step)\n",
    "        D_output_G = D(fake_imgs_G)\n",
    "        \n",
    "        # R_n は G の経験損失 (D を騙せなかった度合い)\n",
    "        # Gは D_output_G が 1 (real_labels) になることを目指す\n",
    "        R_n = bce_loss(D_output_G, real_labels)\n",
    "        \n",
    "        # 3. KLペナルティ KL(q || p) の計算\n",
    "        KL = G.calculate_kl()\n",
    "        \n",
    "        # 4. PAC-Bayes (McAllester) のバウンド\n",
    "        # Bound = R_n(q) + sqrt( (KL(q||p) + log(...)) / 2n )\n",
    "        \n",
    "        complexity_penalty = torch.sqrt( (KL + log_term) / (2 * N_SAMPLES) )\n",
    "        \n",
    "        # 5. 最終的な PAC-Bayes 目的関数 (これを最小化)\n",
    "        # PAC_WEIGHT でペナルティの強さを調整\n",
    "        pac_bayes_loss = R_n + (PAC_WEIGHT * complexity_penalty)\n",
    "        \n",
    "        pac_bayes_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            pbar.set_postfix({\n",
    "                \"D Loss\": f\"{loss_D.item():.4f}\",\n",
    "                \"G (R_n)\": f\"{R_n.item():.4f}\",\n",
    "                \"KL\": f\"{KL.item():.2f}\",\n",
    "                \"Penalty\": f\"{complexity_penalty.item():.4f}\"\n",
    "            })\n",
    "\n",
    "    # --- エポック終了時に画像を保存 ---\n",
    "    G.eval() # 評価モード\n",
    "    with torch.no_grad():\n",
    "        fixed_noise = torch.randn(64, NOISE_DIM).to(device)\n",
    "        sample_weights_for_eval = G.sample_weights()\n",
    "        gen_imgs = G(fixed_noise, sample_weights_for_eval)\n",
    "        gen_imgs = gen_imgs.view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
    "        save_image(gen_imgs, f\"pac_gan_images/epoch_{epoch+1}.png\", normalize=True)\n",
    "    G.train() # 学習モードに戻す\n",
    "\n",
    "print(\"学習完了。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa534f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-sandbox (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
